### Latent Dimension Ablation (d = 2 vs d = 16)

To study the effect of latent capacity, we trained the VAE with a higher latent dimensionality (d=16) while keeping all other hyperparameters fixed. Increasing the latent dimension significantly reduced the reconstruction loss (from approximately 140 to 75 on the test set), indicating improved reconstruction fidelity due to increased representational capacity.

At the same time, the KL divergence increased, reflecting that the encoder makes greater use of the latent variables. This behavior is expected, as a higher-dimensional latent space allows the posterior distribution to deviate more from the prior while still being regularized. Qualitatively, reconstructions and generated samples for d=16 are sharper and more consistent than those for d=2, while latent interpolations remain smooth.

These results highlight the trade-off inherent in VAEs: lower-dimensional latent spaces enforce stronger compression and structure, whereas higher-dimensional spaces improve reconstruction quality at the cost of reduced compression.
